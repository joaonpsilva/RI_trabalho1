https://github.com/joaonpsilva/RI_trabalho1

Jo√£o Silva, 88813
Bernardo Rodrigues, 88835

TOKENIZER 1:

$python3 Indexer.py -tokenizer 1

seconds:  4.668989181518555
Total memory used by program:  134905856 bytes (128.66 Mb)
Vocabulary size:  61050
First 10 terms with 1 doc freq:  ['aaa', 'aaaaaag', 'aaaauga', 'aaac', 'aaag', 'aaap', 'aaars', 'aaas', 'aabb', 'aac']
Higher doc freq terms:  [('the', 26665), ('and', 26576), ('for', 21538), ('with', 21447), ('that', 20276), ('this', 16600), ('from', 15442), ('was', 14470), ('are', 14090), ('were', 13807)]



TOKENIZER 2:

$python3 Indexer.py -tokenizer 2

seconds:  6.0511016845703125
Total memory used by program:  148541440 bytes (141.66 Mb)
Vocabulary size:  110520
First 10 terms with 1 doc freq:  ['0-1', '0-10', '0-131', '0-14', '0-15.3', '0-18.4', '0-182', '0-2', '0-24', '0-2i']
Higher doc freq terms:  [('virus', 14277), ('infect', 13647), ('use', 13591), ('studi', 12683), ('result', 12189), ('diseas', 9644), ('viral', 9336), ('cell', 9168), ('human', 8433), ('protein', 8001)]
